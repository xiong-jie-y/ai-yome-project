# 機械学習モデルの最適化
リアルタイム処理をする場合、機械学習モデルの実行速度を下げる必要が有ることもあります。
学習時とは異なり、推論時には、ネットワークの中に簡易化出来る箇所があり、
そういった箇所を省いたりすることで、処理速度やメモリ使用量を減らしたりします。
また、単純にビット数を落とすことも有効で単精度にしたり、１バイトの引数にしたりしても
ある程度の精度は残せる場合があり、高速化するときは検討しても良いと思います。

モデルの最適化アルゴリズムやランタイムはデバイスや用途に最適化されているので、
自分が推論を行いたいデバイスに特化したものを選ぶ感じになると思います。

!!! todo
    選択基準をもっと作り込む

!!! note
    **OSS参加**
    OSやハードウェアの制約を考えながらパフォーマンスチューニングしたい人とか、性能に関係ない箇所を自動的に探すアルゴリズムを探したい人はこういったOSSに参加するのは楽しいかもしれません。

## TFLiteを使った最適化
[TFLiteはEdgeデバイスの上でモデルを動かすことを想定して作られています。](https://www.tensorflow.org/lite/guide#next_steps)
マルチプラットフォーム、多プログラミング言語対応もそうですが、
パフォーマンス面における特徴としては、

* デバイスに特化した演算単位
* ハードウェアアクセラレーションを活用したKernel
* pre fusedされた活性化とかバイアス
* バイナリサイズが小さい
* [量子化](https://www.tensorflow.org/lite/performance/post_training_quantization#optimization_methods)

デバイスで高速に実行するために、演算が一部の用途に特化した実装になっていたり、
[サポートされている演算に制約](https://www.tensorflow.org/lite/guide/ops_compatibility)があったりするようです。

バイナリサイズが小さいことでモデルのロードが早くなります。

などが上げられる。量子化はCPUで有効で桁を落とすことで並列計算用の機能を活用出来る可能性がある。GPUでも、効果がないわけではないが、そこまで大きな効果があるわけではない。（もともと並列計算するように設計されているため）

## TensorRTを使った最適化
TensorRTはtfliteとは異なり、
データセンター、車、組み込みなど幅広いアプリケーションへの適用を目的としています。
ただ、ハードウェアに関しては、CUDAに限定されそうです。
基本、tfliteと同じで、

* 量子化
* NVIDIAの各種GPU向けの最適化
* LayerやテンソルのFusion

の３つの最適化がされているようです。
