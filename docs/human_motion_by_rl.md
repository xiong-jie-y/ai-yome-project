# 強化学習でヒューマノイドモデルの動作を学習させる
## 頭を撫でる動作の学習：とりあえず動かす
ヒューマノイドモデルはボールを転がす事例と比較して、
次元が大きいので学習の感じがどういう感じか理解するために、
不完全でもいいので、とりあえず、動きを学習させてみました。

## 真面目に環境と報酬関数を設計する

### 単純なモデルで学習を見てみる

### エージェントの環境設計
まずは、エージェントが動作する環境を設計します。

#### 人体制約
頭を撫でるとき人は物理法則がある環境内で筋肉によって複雑に腕を制御していますが、
この環境では、エージェントはアバターの型と肘の角度を自由に調整できるとします。
また、型と肘の角度には制約があるはずなので、人の体の制約に近い制約をActionの処理関数に書きます。

#### 物理制約
また、今は手の位置で報酬を与えていますが、
表面を優しく触ることで報酬をあげたいので、
優しく触っていることを検知刷ることにします。
このあたりの計算をきちんとするために、物理処理あたりをきちんと設定します。

1. ColliderとRigidBodyを手につける。
2. きりたんのおでこにColliderをつける。（MeshColliderでいい）


### 報酬設計
報酬の上げ方としては、次の


こういう人体の制約など物理モデルを簡単に記述出来る方法

### 気になった点
* MeshとColliderの自動設定処理を書く必要がある。あと、Convex化がいまいち。